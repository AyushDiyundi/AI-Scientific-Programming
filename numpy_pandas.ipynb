{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN47jpldQi29"
   },
   "source": [
    "# Intro to NumPy and Pandas\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/giswqs/geog-312/blob/main/book/python/08_numpy_pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chq5PhvqQi2_"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This lecture introduces [NumPy](https://numpy.org) and [Pandas](https://pandas.pydata.org), two fundamental libraries for data manipulation and analysis in Python, with applications in geospatial programming. `NumPy` is essential for numerical operations and handling arrays, while `Pandas` provides powerful tools for data analysis, particularly when working with tabular data. Understanding these libraries will enable you to perform complex data operations efficiently and effectively in geospatial contexts.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lecture, you should be able to:\n",
    "\n",
    "- Understand the basics of `NumPy` arrays and how to perform operations on them.\n",
    "- Utilize `Pandas` DataFrames to organize, analyze, and manipulate tabular data.\n",
    "- Apply `NumPy` and `Pandas` in geospatial programming to process and analyze geospatial datasets.\n",
    "- Combine `NumPy` and `Pandas` to streamline data processing workflows.\n",
    "- Develop the ability to perform complex data operations, such as filtering, aggregating, and transforming geospatial data.\n",
    "\n",
    "## Introduction to NumPy\n",
    "\n",
    "`NumPy` (Numerical Python) is a library used for scientific computing. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "\n",
    "### Creating NumPy Arrays\n",
    "\n",
    "Let's start by creating some basic `NumPy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXpilWfGQi3A"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usJmM6KyQi3B"
   },
   "outputs": [],
   "source": [
    "# Creating a 1D array\n",
    "arr_1d = np.array([1, 2, 3, 4, 5])\n",
    "print(f\"1D Array: {arr_1d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieT2swFrQi3B"
   },
   "outputs": [],
   "source": [
    "# Creating a 2D array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"2D Array:\\n{arr_2d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RXVcqH0EQi3B"
   },
   "outputs": [],
   "source": [
    "# Creating an array of zeros\n",
    "zeros = np.zeros((3, 3))\n",
    "print(f\"Array of zeros:\\n{zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2uj-h4EQi3B"
   },
   "outputs": [],
   "source": [
    "# Creating an array of ones\n",
    "ones = np.ones((2, 4))\n",
    "print(f\"Array of ones:\\n{ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOR0VkEZQi3C"
   },
   "outputs": [],
   "source": [
    "# Creating an array with a range of values\n",
    "range_arr = np.arange(0, 10, 2)\n",
    "print(f\"Range Array: {range_arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLAFCf4XQi3C"
   },
   "source": [
    "### Basic Array Operations\n",
    "\n",
    "`NumPy` allows you to perform element-wise operations on arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_F7veClBQi3C"
   },
   "outputs": [],
   "source": [
    "# Array addition\n",
    "arr_sum = arr_1d + 10\n",
    "print(f\"Array after addition: {arr_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YfFt3VrQi3C"
   },
   "outputs": [],
   "source": [
    "# Array multiplication\n",
    "arr_product = arr_1d * 2\n",
    "print(f\"Array after multiplication: {arr_product}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FlVslMjQi3D"
   },
   "outputs": [],
   "source": [
    "# Element-wise multiplication of two arrays\n",
    "arr_2d_product = arr_2d * np.array([1, 2, 3])\n",
    "print(f\"Element-wise multiplication of 2D array:\\n{arr_2d_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEDQyfM8Qi3D"
   },
   "source": [
    "### Reshaping Arrays\n",
    "\n",
    "Reshaping arrays can be particularly useful when you need to restructure data for specific computations or visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVVF_FpkQi3E"
   },
   "outputs": [],
   "source": [
    "# Reshape a 1D array into a 2D array\n",
    "arr_reshaped = np.arange(12).reshape((3, 4))\n",
    "print(f\"Reshaped 1D Array into 2D Array:\\n{arr_reshaped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9amIAdoQi3E"
   },
   "outputs": [],
   "source": [
    "arr_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gcwWcU-Qi3E"
   },
   "source": [
    "### Mathematical Functions on Arrays\n",
    "\n",
    "You can apply various mathematical functions to arrays, such as square roots, logarithms, and trigonometric functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMinu2H1Qi3E"
   },
   "outputs": [],
   "source": [
    "# Square root of each element in the array\n",
    "sqrt_array = np.sqrt(arr_reshaped)\n",
    "print(f\"Square Root of Array Elements:\\n{sqrt_array}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCzY2GQaQi3E"
   },
   "outputs": [],
   "source": [
    "# Logarithm of each element (add 1 to avoid log(0))\n",
    "log_array = np.log1p(arr_reshaped)\n",
    "print(f\"Logarithm (base e) of Array Elements:\\n{log_array}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSMWbMNFQi3F"
   },
   "source": [
    "### Statistical Operations\n",
    "\n",
    "NumPy provides a wide range of statistical functions for data analysis, such as mean, median, variance, and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6t5Mp1L8Qi3F"
   },
   "outputs": [],
   "source": [
    "# Mean, median, and standard deviation of an array\n",
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "mean_val = np.mean(arr)\n",
    "median_val = np.median(arr)\n",
    "std_val = np.std(arr)\n",
    "\n",
    "print(f\"Mean: {mean_val}, Median: {median_val}, Standard Deviation: {std_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhoWX73eQi3F"
   },
   "source": [
    "### Random Data Generation for Simulation\n",
    "\n",
    "Random data generation is useful for simulations, such as generating random geospatial coordinates or sampling from distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHSdw7bZQi3F"
   },
   "outputs": [],
   "source": [
    "# Generate an array of random latitudes and longitudes\n",
    "random_coords = np.random.uniform(low=-90, high=90, size=(5, 2))\n",
    "print(f\"Random Latitudes and Longitudes:\\n{random_coords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFX3RoWNQi3F"
   },
   "source": [
    "### Indexing, Slicing, and Iterating\n",
    "\n",
    "One of the most powerful features of `NumPy` is its ability to quickly access and modify array elements using indexing and slicing. These operations allow you to select specific parts of the array, which is useful in many geospatial applications where you may want to work with subsets of your data (e.g., focusing on specific regions or coordinates).\n",
    "\n",
    "#### Indexing in NumPy\n",
    "\n",
    "You can access individual elements of an array using their indices. Remember that `NumPy` arrays are zero-indexed, meaning that the first element is at index `0`.\n",
    "\n",
    "Below are some examples of indexing 1D Arrays in `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p00sbK-LQi3F"
   },
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Accessing the first element\n",
    "first_element = arr[0]\n",
    "print(f\"First element: {first_element}\")\n",
    "\n",
    "# Accessing the last element\n",
    "last_element = arr[-1]\n",
    "print(f\"Last element: {last_element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib9eJNmRQi3I"
   },
   "source": [
    "In 2D arrays, you can specify both row and column indices to access a particular element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qhan8ZBQi3J"
   },
   "outputs": [],
   "source": [
    "# Create a 2D array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIplogvCQi3J"
   },
   "outputs": [],
   "source": [
    "# Accessing the element in the first row and second column\n",
    "element = arr_2d[0, 1]\n",
    "print(f\"Element at row 1, column 2: {element}\")\n",
    "\n",
    "# Accessing the element in the last row and last column\n",
    "element_last = arr_2d[-1, -1]\n",
    "print(f\"Element at last row, last column: {element_last}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WN_zuNSEQi3J"
   },
   "source": [
    "#### Slicing in NumPy\n",
    "\n",
    "Slicing allows you to access a subset of an array. You can use the : symbol to specify a range of indices.\n",
    "\n",
    "**Example: Slicing 1D Arrays in NumPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S04xl4AJQi3J"
   },
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Slice elements from index 1 to 3 (exclusive)\n",
    "slice_1d = arr[1:4]\n",
    "print(f\"Slice from index 1 to 3: {slice_1d}\")\n",
    "\n",
    "# Slice all elements from index 2 onwards\n",
    "slice_2d = arr[2:]\n",
    "print(f\"Slice from index 2 onwards: {slice_2d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNpv_fkPQi3J"
   },
   "source": [
    "**Example: Slicing 2D Arrays in NumPy**\n",
    "\n",
    "When slicing a 2D array, you can slice both rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6WbNrA8Qi3K"
   },
   "outputs": [],
   "source": [
    "# Create a 2D array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR20u4HLQi3K"
   },
   "outputs": [],
   "source": [
    "# Slice the first two rows and all columns\n",
    "slice_2d = arr_2d[:2, :]\n",
    "print(f\"Sliced 2D array (first two rows):\\n{slice_2d}\")\n",
    "\n",
    "# Slice the last two rows and the first two columns\n",
    "slice_2d_partial = arr_2d[1:, :2]\n",
    "print(f\"Sliced 2D array (last two rows, first two columns):\\n{slice_2d_partial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz64_aAaQi3K"
   },
   "source": [
    "#### Boolean Indexing\n",
    "\n",
    "You can also use Boolean conditions to filter elements of an array.\n",
    "\n",
    "**Example: Boolean Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBDVs1uJQi3K"
   },
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Boolean condition to select elements greater than 25\n",
    "condition = arr > 25\n",
    "print(f\"Boolean condition: {condition}\")\n",
    "\n",
    "# Use the condition to filter the array\n",
    "filtered_arr = arr[condition]\n",
    "print(f\"Filtered array (elements > 25): {filtered_arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LaJv3K0Qi3K"
   },
   "source": [
    "#### Iterating Over Arrays\n",
    "\n",
    "You can iterate over NumPy arrays to access or modify elements. For 1D arrays, you can simply loop through the elements. For multi-dimensional arrays, you may want to iterate through rows or columns.\n",
    "\n",
    "**Example: Iterating Over a 1D Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXNRMD71Qi3L"
   },
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Iterating through the array\n",
    "for element in arr:\n",
    "    print(f\"Element: {element}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q00fN1qcQi3L"
   },
   "source": [
    "**Example: Iterating Over a 2D Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMbzHKxdQi3L"
   },
   "outputs": [],
   "source": [
    "# Create a 2D array\n",
    "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Iterating through rows of the 2D array\n",
    "print(\"Iterating over rows:\")\n",
    "for row in arr_2d:\n",
    "    print(row)\n",
    "\n",
    "# Iterating through each element of the 2D array\n",
    "print(\"\\nIterating over each element:\")\n",
    "for row in arr_2d:\n",
    "    for element in row:\n",
    "        print(element, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzEfbFqxQi3L"
   },
   "source": [
    "### Modifying Array Elements\n",
    "\n",
    "You can also use indexing and slicing to modify elements of the array.\n",
    "\n",
    "**Example: Modifying Elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrcRMcrUQi3Q"
   },
   "outputs": [],
   "source": [
    "# Create a 1D array\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "# Modify the element at index 1\n",
    "arr[1] = 25\n",
    "print(f\"Modified array: {arr}\")\n",
    "\n",
    "# Modify multiple elements using slicing\n",
    "arr[2:4] = [35, 45]\n",
    "print(f\"Modified array with slicing: {arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roYTh-mrQi3Q"
   },
   "source": [
    "### Working with Geospatial Coordinates\n",
    "\n",
    "You can use `NumPy` to perform calculations on arrays of geospatial coordinates, such as converting from degrees to radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAyINJJmQi3R"
   },
   "outputs": [],
   "source": [
    "# Array of latitudes and longitudes\n",
    "coords = np.array([[35.6895, 139.6917], [34.0522, -118.2437], [51.5074, -0.1278]])\n",
    "\n",
    "# Convert degrees to radians\n",
    "coords_radians = np.radians(coords)\n",
    "print(f\"Coordinates in radians:\\n{coords_radians}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqpkzT3JQi3R"
   },
   "source": [
    "## Introduction to Pandas\n",
    "\n",
    "`Pandas` is a powerful data manipulation library that provides data structures like Series and DataFrames to work with structured data. It is especially useful for handling tabular data.\n",
    "\n",
    "### Creating Pandas Series and DataFrames\n",
    "\n",
    "Let's create a `Pandas` Series and DataFrame. Each column in a DataFrame is a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx6uM98FQi3R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8c6gVtVQi3R"
   },
   "outputs": [],
   "source": [
    "# Creating a Series\n",
    "city_series = pd.Series([\"Tokyo\", \"Los Angeles\", \"London\"], name=\"City\")\n",
    "print(f\"Pandas Series:\\n{city_series}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yW1ki2z1Qi3R"
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    \"City\": [\"Tokyo\", \"Los Angeles\", \"London\"],\n",
    "    \"Latitude\": [35.6895, 34.0522, 51.5074],\n",
    "    \"Longitude\": [139.6917, -118.2437, -0.1278],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Pandas DataFrame:\\n{df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQ1B5zEFQi3S"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxa6jGEEQi3S"
   },
   "source": [
    "### Basic DataFrame Operations\n",
    "\n",
    "You can perform various operations on `Pandas` DataFrames, such as filtering, selecting specific columns, and applying functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Al6Yf2rmQi3S"
   },
   "outputs": [],
   "source": [
    "# Selecting a specific column\n",
    "latitudes = df[\"Latitude\"]\n",
    "print(f\"Latitudes:\\n{latitudes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKBcSKrKQi3S"
   },
   "outputs": [],
   "source": [
    "# Filtering rows based on a condition\n",
    "df_filtered = df[df[\"Longitude\"] < 0]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qv1wErCVQi3S"
   },
   "outputs": [],
   "source": [
    "# Adding a new column with a calculation\n",
    "df[\"Lat_Radians\"] = np.radians(df[\"Latitude\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THYOL5r4Qi3T"
   },
   "source": [
    "### Grouping and Aggregation\n",
    "\n",
    "Pandas allows you to group data and perform aggregate functions, which is useful in summarizing large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Atwcx0ywQi3T"
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame\n",
    "data = {\n",
    "    \"City\": [\"Tokyo\", \"Los Angeles\", \"London\", \"Paris\", \"Chicago\"],\n",
    "    \"Country\": [\"Japan\", \"USA\", \"UK\", \"France\", \"USA\"],\n",
    "    \"Population\": [37400068, 3970000, 9126366, 2140526, 2665000],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-7_Xp_GQi3T"
   },
   "outputs": [],
   "source": [
    "# Group by 'Country' and calculate the total population for each country\n",
    "df_grouped = df.groupby(\"Country\")[\"Population\"].sum()\n",
    "print(f\"Total Population by Country:\\n{df_grouped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87Culk4uQi3T"
   },
   "source": [
    "### Merging DataFrames\n",
    "\n",
    "Merging datasets is essential when combining different geospatial datasets, such as joining city data with demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZM21MiDQi3U"
   },
   "outputs": [],
   "source": [
    "# Creating two DataFrames to merge\n",
    "df1 = pd.DataFrame(\n",
    "    {\"City\": [\"Tokyo\", \"Los Angeles\", \"London\"], \"Country\": [\"Japan\", \"USA\", \"UK\"]}\n",
    ")\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"City\": [\"Tokyo\", \"Los Angeles\", \"London\"],\n",
    "        \"Population\": [37400068, 3970000, 9126366],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yx0hZPWCQi3U"
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsRi5Tc1Qi3U"
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA2L-RjoQi3U"
   },
   "outputs": [],
   "source": [
    "# Merge the two DataFrames on the 'City' column\n",
    "df_merged = pd.merge(df1, df2, on=\"City\")\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l3we0_nQi3U"
   },
   "source": [
    "### Handling Missing Data\n",
    "\n",
    "In real-world datasets, missing data is common. Pandas provides tools to handle missing data, such as filling or removing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JCGrgKjQi3V"
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame with missing values\n",
    "data_with_nan = {\n",
    "    \"City\": [\"Tokyo\", \"Los Angeles\", \"London\", \"Paris\"],\n",
    "    \"Population\": [37400068, 3970000, None, 2140526],\n",
    "}\n",
    "df_nan = pd.DataFrame(data_with_nan)\n",
    "df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBb2BV-zQi3V"
   },
   "outputs": [],
   "source": [
    "# Fill missing values with the mean population\n",
    "df_filled = df_nan.fillna(df_nan[\"Population\"].mean())\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZE4wbKiQi3V"
   },
   "source": [
    "### Reading Geospatial Data from a CSV File\n",
    "\n",
    "Pandas can read and write data in various formats, such as CSV, Excel, and SQL databases. This makes it easy to load and save data from different sources. For example, you can read a CSV file into a Pandas DataFrame and then perform operations on the data.\n",
    "\n",
    "Let's read a CSV file from an HTTP URL into a Pandas DataFrame and display the first few rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mi2byy4tQi3V"
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/opengeos/datasets/releases/download/world/world_cities.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocA-xPncQi3W"
   },
   "source": [
    "The DataFrame contains information about world cities, including their names, countries, populations, and geographical coordinates. We can calculate the total population of all cities in the dataset using NumPy and Pandas as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilRlatTXQi3W"
   },
   "outputs": [],
   "source": [
    "np.sum(df[\"population\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7KjMbmMQi3W"
   },
   "source": [
    "### Creating plots with Pandas\n",
    "\n",
    "Pandas provides built-in plotting capabilities that allow you to create various types of plots directly from DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Brss66cTQi3W"
   },
   "outputs": [],
   "source": [
    "# Load the dataset from an online source\n",
    "url = \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2.csv\"\n",
    "air_quality = pd.read_csv(url, index_col=0, parse_dates=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "air_quality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCnv1UijQi3W"
   },
   "source": [
    "To do a quick visual check of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjF0eRKAQi3W"
   },
   "outputs": [],
   "source": [
    "air_quality.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kdLcMovQi3X"
   },
   "source": [
    "To plot only the columns of the data table with the data from Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utf4UpKKQi3X"
   },
   "outputs": [],
   "source": [
    "air_quality[\"station_paris\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVnOeYzpQi3X"
   },
   "source": [
    "To visually compare the values measured in London versus Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBvI6QP9Qi3X"
   },
   "outputs": [],
   "source": [
    "air_quality.plot.scatter(x=\"station_london\", y=\"station_paris\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJAsfRnnQi3X"
   },
   "source": [
    "To visualize each of the columns in a separate subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuQWopMmQi3Y"
   },
   "outputs": [],
   "source": [
    "air_quality.plot.area(figsize=(12, 4), subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUV8St93Qi3Y"
   },
   "source": [
    "### Analyzing Geospatial Data\n",
    "\n",
    "In this example, we analyze a dataset of cities, calculating the distance between each pair using the Haversine formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uogQ9OvQi3Y"
   },
   "outputs": [],
   "source": [
    "# Define the Haversine formula using NumPy\n",
    "def haversine_np(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Earth radius in kilometers\n",
    "    dlat = np.radians(lat2 - lat1)\n",
    "    dlon = np.radians(lon2 - lon1)\n",
    "    a = (\n",
    "        np.sin(dlat / 2) ** 2\n",
    "        + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2)) * np.sin(dlon / 2) ** 2\n",
    "    )\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Create a new DataFrame with city pairs\n",
    "city_pairs = pd.DataFrame(\n",
    "    {\n",
    "        \"City1\": [\"Tokyo\", \"Tokyo\", \"Los Angeles\"],\n",
    "        \"City2\": [\"Los Angeles\", \"London\", \"London\"],\n",
    "        \"Lat1\": [35.6895, 35.6895, 34.0522],\n",
    "        \"Lon1\": [139.6917, 139.6917, -118.2437],\n",
    "        \"Lat2\": [34.0522, 51.5074, 51.5074],\n",
    "        \"Lon2\": [-118.2437, -0.1278, -0.1278],\n",
    "    }\n",
    ")\n",
    "city_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7-tspz8Qi3Y"
   },
   "outputs": [],
   "source": [
    "# Calculate distances between city pairs\n",
    "city_pairs[\"Distance_km\"] = haversine_np(\n",
    "    city_pairs[\"Lat1\"], city_pairs[\"Lon1\"], city_pairs[\"Lat2\"], city_pairs[\"Lon2\"]\n",
    ")\n",
    "city_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiccDaUNQi3Y"
   },
   "source": [
    "## Combining NumPy and Pandas\n",
    "\n",
    "You can combine `NumPy` and `Pandas` to perform complex data manipulations. For instance, you might want to apply `NumPy` functions to a `Pandas` DataFrame or use `Pandas` to organize and visualize the results of `NumPy` operations.\n",
    "\n",
    "Let's say you have a dataset of cities, and you want to calculate the average distance from each city to all other cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYO67xVhQi3Z"
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate distances from a city to all other cities\n",
    "def calculate_average_distance(df):\n",
    "    lat1 = df[\"Latitude\"].values\n",
    "    lon1 = df[\"Longitude\"].values\n",
    "    lat2, lon2 = np.meshgrid(lat1, lon1)\n",
    "    distances = haversine_np(lat1, lon1, lat2, lon2)\n",
    "    avg_distances = np.mean(distances, axis=1)\n",
    "    return avg_distances\n",
    "\n",
    "\n",
    "# Creating a DataFrame\n",
    "data = {\n",
    "    \"City\": [\"Tokyo\", \"Los Angeles\", \"London\"],\n",
    "    \"Latitude\": [35.6895, 34.0522, 51.5074],\n",
    "    \"Longitude\": [139.6917, -118.2437, -0.1278],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the function to calculate average distances\n",
    "df[\"Avg_Distance_km\"] = calculate_average_distance(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZRJCwtEQi3Z"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Array Operations**: Create a `NumPy` array representing the elevations of various locations. Normalize the elevations (e.g., subtract the mean and divide by the standard deviation) and calculate the mean and standard deviation of the normalized array.\n",
    "2. **Data Analysis with Pandas**: Create a `Pandas` DataFrame from a CSV file containing geospatial data (e.g., cities and their coordinates). Filter the DataFrame to include only cities in the Northern Hemisphere and calculate the average latitude of these cities.\n",
    "3. **Combining NumPy and Pandas**: Using a dataset of geographic coordinates, create a `Pandas` DataFrame. Use `NumPy` to calculate the pairwise distances between all points and store the results in a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dc9LH1bdQi3Z",
    "ExecuteTime": {
     "end_time": "2026-02-03T11:56:51.239557700Z",
     "start_time": "2026-02-03T11:56:51.185935400Z"
    }
   },
   "source": [
    "# Exercise 1: Array Operations\n",
    "import numpy as np\n",
    "elevations = np.array([150, 320, 580, 1200, 450, 890, 2100, 340, 670, 1050])\n",
    "\n",
    "print(\"Original Elevations (meters):\")\n",
    "print(elevations)\n",
    "print()\n",
    "\n",
    "mean_elevation = np.mean(elevations)\n",
    "std_elevation = np.std(elevations)\n",
    "\n",
    "print(\"Statistics of Original Data:\")\n",
    "print(f\"Mean elevation: {mean_elevation:.2f} meters\")\n",
    "print(f\"Standard deviation: {std_elevation:.2f} meters\")\n",
    "print()\n",
    "\n",
    "normalized_elevations = (elevations - mean_elevation) / std_elevation\n",
    "\n",
    "print(\"Normalized Elevations:\")\n",
    "print(normalized_elevations)\n",
    "print()\n",
    "\n",
    "normalized_mean = np.mean(normalized_elevations)\n",
    "normalized_std = np.std(normalized_elevations)\n",
    "\n",
    "print(\"Statistics of Normalized Data:\")\n",
    "print(f\"Mean: {normalized_mean:.10f}\")\n",
    "print(f\"Standard deviation: {normalized_std:.10f}\")\n",
    "print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Elevations (meters):\n",
      "[ 150  320  580 1200  450  890 2100  340  670 1050]\n",
      "\n",
      "Statistics of Original Data:\n",
      "Mean elevation: 775.00 meters\n",
      "Standard deviation: 544.67 meters\n",
      "\n",
      "Normalized Elevations:\n",
      "[-1.14748459 -0.83536878 -0.35801519  0.78028952 -0.59669199  0.21113716\n",
      "  2.43266733 -0.79864927 -0.19277741  0.50489322]\n",
      "\n",
      "Statistics of Normalized Data:\n",
      "Mean: -0.0000000000\n",
      "Standard deviation: 1.0000000000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T12:13:07.797162700Z",
     "start_time": "2026-02-03T12:13:07.325791600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Exercise 2: Data Analysis with Pandas\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Create sample CSV data with cities and their coordinates\n",
    "csv_data = \"\"\"city,latitude,longitude,country,population\n",
    "Tokyo,35.6762,139.6503,Japan,13960000\n",
    "New York,40.7128,-74.0060,USA,8336817\n",
    "London,51.5074,-0.1278,United Kingdom,8982000\n",
    "Sydney,-33.8688,151.2093,Australia,5312000\n",
    "Paris,48.8566,2.3522,France,2161000\n",
    "Mumbai,19.0760,72.8777,India,20411000\n",
    "São Paulo,-23.5505,-46.6333,Brazil,12326000\n",
    "Moscow,55.7558,37.6173,Russia,12506468\n",
    "Cairo,30.0444,31.2357,Egypt,9500000\n",
    "Buenos Aires,-34.6037,-58.3816,Argentina,3075000\n",
    "Singapore,1.3521,103.8198,Singapore,5686000\n",
    "Melbourne,-37.8136,144.9631,Australia,5078000\n",
    "Beijing,39.9042,116.4074,China,21540000\n",
    "Cape Town,-33.9249,18.4241,South Africa,4618000\n",
    "\"\"\"\n",
    "\n",
    "df_cities = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "print(\"All Cities Dataset:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_cities)\n",
    "print()\n",
    "\n",
    "print(f\"Total number of cities: {len(df_cities)}\")\n",
    "print(f\"Columns: {list(df_cities.columns)}\")\n",
    "print()\n",
    "\n",
    "northern_cities = df_cities[df_cities['latitude'] > 0]\n",
    "\n",
    "print(\"Cities in the Northern Hemisphere:\")\n",
    "print(\"=\" * 80)\n",
    "print(northern_cities)\n",
    "print()\n",
    "\n",
    "avg_latitude = northern_cities['latitude'].mean()\n",
    "min_latitude = northern_cities['latitude'].min()\n",
    "max_latitude = northern_cities['latitude'].max()\n",
    "count_northern = len(northern_cities)\n",
    "\n",
    "print(\"Northern Hemisphere Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Number of cities: {count_northern}\")\n",
    "print(f\"Average latitude: {avg_latitude:.4f}°\")\n",
    "min_row = northern_cities.loc[northern_cities['latitude'].idxmin()]\n",
    "max_row = northern_cities.loc[northern_cities['latitude'].idxmax()]\n",
    "print(f\"Minimum latitude: {min_row['latitude']:.4f}° ({min_row['city']})\")\n",
    "print(f\"Maximum latitude: {max_row['latitude']:.4f}° ({max_row['city']})\")\n",
    "print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Cities Dataset:\n",
      "================================================================================\n",
      "            city  latitude  longitude         country  population\n",
      "0          Tokyo   35.6762   139.6503           Japan    13960000\n",
      "1       New York   40.7128   -74.0060             USA     8336817\n",
      "2         London   51.5074    -0.1278  United Kingdom     8982000\n",
      "3         Sydney  -33.8688   151.2093       Australia     5312000\n",
      "4          Paris   48.8566     2.3522          France     2161000\n",
      "5         Mumbai   19.0760    72.8777           India    20411000\n",
      "6      São Paulo  -23.5505   -46.6333          Brazil    12326000\n",
      "7         Moscow   55.7558    37.6173          Russia    12506468\n",
      "8          Cairo   30.0444    31.2357           Egypt     9500000\n",
      "9   Buenos Aires  -34.6037   -58.3816       Argentina     3075000\n",
      "10     Singapore    1.3521   103.8198       Singapore     5686000\n",
      "11     Melbourne  -37.8136   144.9631       Australia     5078000\n",
      "12       Beijing   39.9042   116.4074           China    21540000\n",
      "13     Cape Town  -33.9249    18.4241    South Africa     4618000\n",
      "\n",
      "Total number of cities: 14\n",
      "Columns: ['city', 'latitude', 'longitude', 'country', 'population']\n",
      "\n",
      "Cities in the Northern Hemisphere:\n",
      "================================================================================\n",
      "         city  latitude  longitude         country  population\n",
      "0       Tokyo   35.6762   139.6503           Japan    13960000\n",
      "1    New York   40.7128   -74.0060             USA     8336817\n",
      "2      London   51.5074    -0.1278  United Kingdom     8982000\n",
      "4       Paris   48.8566     2.3522          France     2161000\n",
      "5      Mumbai   19.0760    72.8777           India    20411000\n",
      "7      Moscow   55.7558    37.6173          Russia    12506468\n",
      "8       Cairo   30.0444    31.2357           Egypt     9500000\n",
      "10  Singapore    1.3521   103.8198       Singapore     5686000\n",
      "12    Beijing   39.9042   116.4074           China    21540000\n",
      "\n",
      "Northern Hemisphere Statistics:\n",
      "================================================================================\n",
      "Number of cities: 9\n",
      "Average latitude: 35.8762°\n",
      "Minimum latitude: 1.3521° (Singapore)\n",
      "Maximum latitude: 55.7558° (Moscow)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-03T12:25:33.855710900Z",
     "start_time": "2026-02-03T12:25:33.786027100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Exercise 3: Combining NumPy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataset of geographic coordinates\n",
    "coordinates_data = {\n",
    "    'location': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'San Francisco'],\n",
    "    'latitude': [40.7128, 34.0522, 41.8781, 29.7604, 37.7749],\n",
    "    'longitude': [-74.0060, -118.2437, -87.6298, -95.3698, -122.4194]\n",
    "}\n",
    "\n",
    "df_coords = pd.DataFrame(coordinates_data)\n",
    "\n",
    "print(\"Geographic Coordinates Dataset:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_coords)\n",
    "print()\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points on Earth\n",
    "    using the Haversine formula.\n",
    "\n",
    "    Parameters:\n",
    "        lat1, lon1: Latitude and longitude of point 1 (in degrees)\n",
    "        lat2, lon2: Latitude and longitude of point 2 (in degrees)\n",
    "\n",
    "    Returns:\n",
    "        Distance in kilometers\n",
    "    \"\"\"\n",
    "    # Convert degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # Earth's radius in kilometers\n",
    "    radius_earth = 6371\n",
    "\n",
    "    return c * radius_earth\n",
    "\n",
    "n_points = len(df_coords)\n",
    "distance_matrix = np.zeros((n_points, n_points))\n",
    "\n",
    "for i in range(n_points):\n",
    "    for j in range(n_points):\n",
    "        if i != j:\n",
    "            distance_matrix[i, j] = haversine_distance(\n",
    "                df_coords.loc[i, 'latitude'],\n",
    "                df_coords.loc[i, 'longitude'],\n",
    "                df_coords.loc[j, 'latitude'],\n",
    "                df_coords.loc[j, 'longitude']\n",
    "            )\n",
    "\n",
    "# Create DataFrame with distance matrix\n",
    "df_distances = pd.DataFrame(\n",
    "    distance_matrix,\n",
    "    index=df_coords['location'],\n",
    "    columns=df_coords['location']\n",
    ")\n",
    "\n",
    "print(\"Pairwise Distance Matrix (in kilometers):\")\n",
    "print(\"=\" * 80)\n",
    "print(df_distances.round(2))\n",
    "print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geographic Coordinates Dataset:\n",
      "================================================================================\n",
      "        location  latitude  longitude\n",
      "0       New York   40.7128   -74.0060\n",
      "1    Los Angeles   34.0522  -118.2437\n",
      "2        Chicago   41.8781   -87.6298\n",
      "3        Houston   29.7604   -95.3698\n",
      "4  San Francisco   37.7749  -122.4194\n",
      "\n",
      "Pairwise Distance Matrix (in kilometers):\n",
      "================================================================================\n",
      "location       New York  Los Angeles  Chicago  Houston  San Francisco\n",
      "location                                                             \n",
      "New York           0.00      3935.75  1144.29  2281.34        4129.09\n",
      "Los Angeles     3935.75         0.00  2803.97  2206.26         559.12\n",
      "Chicago         1144.29      2803.97     0.00  1515.81        2984.91\n",
      "Houston         2281.34      2206.26  1515.81     0.00        2643.05\n",
      "San Francisco   4129.09       559.12  2984.91  2643.05           0.00\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "zTguK1UeQi3Z"
   },
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "`NumPy` and `Pandas` are essential tools in geospatial programming, allowing you to efficiently manipulate and analyze numerical and tabular data. By mastering these libraries, you will be able to perform complex data operations, manage large datasets, and streamline your geospatial workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
